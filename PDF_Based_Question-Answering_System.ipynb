{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5115a674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\kurak\\anaconda3\\lib\\site-packages (4.39.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\kurak\\anaconda3\\lib\\site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\kurak\\anaconda3\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kurak\\anaconda3\\lib\\site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\kurak\\anaconda3\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\kurak\\anaconda3\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\kurak\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\kurak\\anaconda3\\lib\\site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\kurak\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\kurak\\anaconda3\\lib\\site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: requests in c:\\users\\kurak\\anaconda3\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\kurak\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\kurak\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kurak\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kurak\\anaconda3\\lib\\site-packages (from requests->transformers) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\kurak\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\kurak\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kurak\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb5c1111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in c:\\users\\kurak\\anaconda3\\lib\\site-packages (3.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "438321d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\kurak\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\kurak\\anaconda3\\lib\\site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\kurak\\anaconda3\\lib\\site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kurak\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\kurak\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\kurak\\anaconda3\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: sympy in c:\\users\\kurak\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kurak\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\kurak\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abf66687",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required packages\n",
    "import torch\n",
    "from transformers import BertForQuestionAnswering\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68f0b9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox, scrolledtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e02d80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d9ea0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# create bert model for question answering\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "# define tokenizer for bert\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eea88b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_qa(question, context, max_len=500):\n",
    "\n",
    "    #Tokenize input question and passage \n",
    "    #Add special tokens - [CLS] and [SEP]\n",
    "    input_ids = tokenizer.encode (question, context,  max_length= max_len, truncation=True)  \n",
    "\n",
    "    #Getting number of tokens in question and context passage that contains the answer\n",
    "    sep_index = input_ids.index(102) \n",
    "    len_question = sep_index + 1   \n",
    "    len_context = len(input_ids)- len_question  \n",
    "    \n",
    "    #Separate question and context \n",
    "    #Segment ids will be 0 for question and 1 for context\n",
    "    segment_ids =  [0]*len_question + [1]*(len_context)  \n",
    "    \n",
    "    #Converting token ids to tokens\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids) \n",
    "\n",
    "    #Getting start and end scores for answer\n",
    "    #Converting input arrays to torch tensors before passing to the model\n",
    "    start_token_scores = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([segment_ids]) )[0]\n",
    "    end_token_scores = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([segment_ids]) )[1]\n",
    "\n",
    "    #Converting scores tensors to numpy arrays\n",
    "    start_token_scores = start_token_scores.detach().numpy().flatten()\n",
    "    end_token_scores = end_token_scores.detach().numpy().flatten()\n",
    "\n",
    "    #Getting start and end index of answer based on highest scores\n",
    "    answer_start_index = np.argmax(start_token_scores)\n",
    "    answer_end_index = np.argmax(end_token_scores)\n",
    "\n",
    "    #Getting scores for start and end token of the answer\n",
    "    start_token_score = np.round(start_token_scores[answer_start_index], 2)\n",
    "    end_token_score = np.round(end_token_scores[answer_end_index], 2)\n",
    "\n",
    "    #Combining subwords starting with ## and get full words in output. \n",
    "    #It is because tokenizer breaks words which are not in its vocab.\n",
    "    answer = tokens[answer_start_index] \n",
    "    for i in range(answer_start_index + 1, answer_end_index + 1):\n",
    "        if tokens[i][0:2] == '##':  \n",
    "            answer += tokens[i][2:] \n",
    "        else:\n",
    "            answer += ' ' + tokens[i]  \n",
    "\n",
    "    # If the answer not in the passage\n",
    "    if ( answer_start_index == 0) or (start_token_score < 0 ) or  (answer == '[SEP]') or ( answer_end_index <  answer_start_index):\n",
    "        answer = \"Sorry, Couldn't find answer in given pdf. Please try again!\"\n",
    "    \n",
    "    return (answer_start_index, answer_end_index, start_token_score, end_token_score,  answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "961ede60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox, scrolledtext\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def select_file():\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"PDF files\", \"*.pdf\")])\n",
    "    if file_path:\n",
    "        file_entry.delete(0, tk.END)\n",
    "        file_entry.insert(0, file_path)\n",
    "\n",
    "def get_answer():\n",
    "    file_path = file_entry.get()\n",
    "    question = question_entry.get()\n",
    "    \n",
    "    if not file_path or not question:\n",
    "        messagebox.showwarning(\"Input Error\", \"Please select a PDF file and enter a question.\")\n",
    "        return\n",
    "    \n",
    "    pdf_reader = PdfReader(open(file_path, 'rb'))\n",
    "    text = \"\"\n",
    "    \n",
    "    for page in pdf_reader.pages:\n",
    "        text += page.extract_text()\n",
    "    \n",
    "    answer = bert_qa(question, text)\n",
    "    output_text.delete(1.0, tk.END)\n",
    "    output_text.insert(tk.END, answer)\n",
    "\n",
    "def on_closing():\n",
    "    root.quit()\n",
    "    root.destroy()\n",
    "\n",
    "# Create the main Tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Question-Answering System using BERT\")\n",
    "root.configure(bg=\"#34495E\")  # Dark blue-gray background\n",
    "root.protocol(\"WM_DELETE_WINDOW\", on_closing)\n",
    "\n",
    "# Create and place widgets\n",
    "tk.Label(root, text=\"Select a PDF file:\", bg=\"#34495E\", fg=\"#ECF0F1\", font=(\"Arial\", 10)).grid(row=0, column=0, padx=10, pady=5, sticky=\"W\")\n",
    "file_entry = tk.Entry(root, width=50, bg=\"#ECF0F1\", fg=\"#34495E\", font=(\"Arial\", 10))\n",
    "file_entry.grid(row=0, column=1, padx=10, pady=5)\n",
    "tk.Button(root, text=\"Browse\", command=select_file, bg=\"#1ABC9C\", fg=\"#FFFFFF\", font=(\"Arial\", 10)).grid(row=0, column=2, padx=10, pady=5)\n",
    "\n",
    "tk.Label(root, text=\"Enter question:\", bg=\"#34495E\", fg=\"#ECF0F1\", font=(\"Arial\", 10)).grid(row=1, column=0, padx=10, pady=5, sticky=\"W\")\n",
    "question_entry = tk.Entry(root, width=50, bg=\"#ECF0F1\", fg=\"#34495E\", font=(\"Arial\", 10))\n",
    "question_entry.grid(row=1, column=1, columnspan=2, padx=10, pady=5)\n",
    "\n",
    "tk.Button(root, text=\"Submit\", command=get_answer, bg=\"#1ABC9C\", fg=\"#FFFFFF\", font=(\"Arial\", 10)).grid(row=2, column=1, columnspan=2, padx=10, pady=10)\n",
    "\n",
    "tk.Label(root, text=\"Answer:\", bg=\"#34495E\", fg=\"#ECF0F1\", font=(\"Arial\", 10)).grid(row=3, column=0, padx=10, pady=5, sticky=\"W\")\n",
    "output_text = scrolledtext.ScrolledText(root, width=60, height=10, font=(\"Arial\", 10), bg=\"#2C3E50\", fg=\"#ECF0F1\")\n",
    "output_text.grid(row=3, column=1, columnspan=2, padx=10, pady=5)\n",
    "\n",
    "# Start the Tkinter event loop\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb54b49b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
